Data ingestion: Kafka

storage: postgres

use aws

close example https://mapr.com/blog/fast-data-processing-pipeline-predicting-flight-delays-using-apache-apis-pt-3/
spark tutorial: https://www.tutorialspoint.com/pyspark/pyspark_environment_setup.htm

use postgres

and spark to talk to postgres

data:
- citibike: real time streaming
- weather: hourly

app:
- flask / redux / react

helpful background links:
- data stacks: https://blog.keen.io/architecture-of-giants-data-stacks-at-facebook-netflix-airbnb-and-pinterest-9b7cd881af54
- spark streaming: https://spark.apache.org/docs/latest/streaming-programming-guide.html
- zookeeper https://www.quora.com/What-is-the-actual-role-of-Zookeeper-in-Kafka-What-benefits-will-I-miss-out-on-if-I-don%E2%80%99t-use-Zookeeper-and-Kafka-together

Step 1:
- figure out how to get streaming realtime data from citibike into the kafka tutorial

Step 2:
- save citibike data from kafka to a postgresql database as it comes in


other traiing data
https://www.kaggle.com/marklvl/bike-sharing-dataset
